{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run this before starting\n",
    "!python -c \"import torch; print(torch.__version__)\"\n",
    "!python -c \"import torch; print(torch.version.cuda)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn.conv import feast_conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device_name = torch.device(\"cuda\")\n",
    "else:\n",
    "    device_name = torch.device('cpu')\n",
    "\n",
    "print(\"Using {}.\".format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969\n",
      "657\n",
      "torch.Size([20, 3])\n",
      "torch.Size([2, 38])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "#TxtFile to lists\n",
    "import numpy as np \n",
    "import random\n",
    "#data = np.loadtxt('C:\\\\Users\\\\eliasak\\\\OneDrive - NTNU\\\\Master thesis\\\\07_ML\\\\ArchGNN\\\\data.txt')\n",
    "megadata = \"m2Data.txt\"\n",
    "def create_dataset(filePath):\n",
    "  values_list = []  # create an empty list to store the values for each row\n",
    "  x = []\n",
    "  z = []\n",
    "  m = []\n",
    "  l = []\n",
    "\n",
    "  with open(filePath, \"r\") as f:\n",
    "      for line in f:  # loop over each line in the file\n",
    "          values = line.strip().split(\"\\t\")  # split the line into a list of strings\n",
    "\n",
    "          xL = []\n",
    "          zL = []\n",
    "          mL = []\n",
    "          lL = []\n",
    "\n",
    "          for i in range(20):\n",
    "              xL.append(round(float(values[i]),3))\n",
    "              zL.append(round(float(values[i+20]),3))\n",
    "              mL.append(round(float(values[i+20*2]),3))\n",
    "              try:\n",
    "                  lL.append(round(float(values[i+20*3]),3))\n",
    "              except:\n",
    "                  None\n",
    "          x.append(xL)\n",
    "          z.append(zL)\n",
    "          m.append(mL)\n",
    "          l.append(lL)\n",
    "\n",
    "\n",
    "  dataY = []\n",
    "\n",
    "  dataX = []\n",
    "  for i in range(len(x)):\n",
    "      dataXs = []\n",
    "      for j in range(0,len(x[i])):\n",
    "          dataX0 = []\n",
    "          dataX0.append(j)\n",
    "          dataX0.append(x[i][j])\n",
    "          dataX0.append(z[i][j])\n",
    "          dataXs.append(dataX0)\n",
    "      dataX.append(dataXs)\n",
    "\n",
    "  dataY = m\n",
    "  zipped = list(zip(dataX, dataY))\n",
    "  random.shuffle(zipped)\n",
    "  dataX, dataY = zip(*zipped)\n",
    "\n",
    "  dataX = np.array(dataX)\n",
    "  dataY = np.array(dataY)\n",
    "\n",
    "  dataEgdeIndex = []\n",
    "  for i in range(len(x[0])-1):\n",
    "      dataEgdeIndex.append([i,i+1])\n",
    "      dataEgdeIndex.append([i+1,i])  \n",
    "\n",
    "  dataEgdeIndex = np.array(dataEgdeIndex) \n",
    "  dataEgdeIndex =np.transpose(dataEgdeIndex)\n",
    "\n",
    "\n",
    "\n",
    "  input_data = dataX\n",
    "  target_data = dataY\n",
    "  edge_index = dataEgdeIndex\n",
    "  dataX = torch.from_numpy(dataX)\n",
    "  dataY = torch.from_numpy(dataY)\n",
    "  edge_index = torch.from_numpy(edge_index)\n",
    "  edge_index = edge_index.to(torch.long)\n",
    "  dataX = dataX.to(torch.float)\n",
    "  dataY = dataY.to(torch.float)\n",
    "\n",
    "\n",
    "\n",
    "  dataset = []\n",
    "  for i in range(dataX.shape[0]):\n",
    "      dataset.append(Data(x=dataX[i], edge_index=edge_index, y=dataY[i]))\n",
    "  return dataset\n",
    "dataset = create_dataset(megadata)\n",
    "train_loader = dataset[:int(len(dataset)*0.75)]\n",
    "test_loader = dataset[int(len(dataset)*0.75):]\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))\n",
    "\n",
    "\n",
    "# one data object from train_loader:\n",
    "graph = train_loader[0]\n",
    "\n",
    "print(graph.x.shape)\n",
    "print(graph.edge_index.shape)\n",
    "print(graph.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArchNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, heads, t_inv = True):\n",
    "        super(ArchNN, self).__init__()\n",
    "        self.fc0 = nn.Linear(in_channels, 16)\n",
    "        self.conv1 = feast_conv.FeaStConv(16, 32, heads=heads, t_inv=t_inv)\n",
    "        self.conv2 = feast_conv.FeaStConv(32, 64, heads=heads, t_inv=t_inv)\n",
    "        self.conv3 = feast_conv.FeaStConv(64, 128, heads=heads, t_inv=t_inv)\n",
    "        #self.conv4 = feast_conv.FeaStConv(128, 256, heads=heads, t_inv=t_inv)\n",
    "        #self.conv5 = feast_conv.FeaStConv(256, 512, heads=heads, t_inv=t_inv)\n",
    "        #self.conv6 = feast_conv.FeaStConv(512, 256, heads=heads, t_inv=t_inv)\n",
    "        #self.conv7 = feast_conv.FeaStConv(256, 128, heads=heads, t_inv=t_inv)\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "        self.conv3.reset_parameters()\n",
    "        #self.conv4.reset_parameters()\n",
    "        #self.conv5.reset_parameters()\n",
    "        #self.conv6.reset_parameters()\n",
    "        #self.conv7.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.elu(self.fc0(x))\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.elu(self.conv2(x, edge_index))\n",
    "        x = F.elu(self.conv3(x, edge_index))\n",
    "        #x = F.elu(self.conv4(x, edge_index))\n",
    "        #x = F.elu(self.conv5(x, edge_index))\n",
    "        #x = F.elu(self.conv6(x, edge_index))\n",
    "        #x = F.elu(self.conv7(x, edge_index))\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        #F.log_softmax(x, dijm=1)\n",
    "        x = torch.squeeze(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def print_info(info):\n",
    "    message = ('Epoch: {}/{}, Duration: {:.3f}s,'\n",
    "               'Train Loss: {:.4f}, Test Loss:{:.4f}').format(\n",
    "                   info['current_epoch'], info['epochs'], info['t_duration'],\n",
    "                   info['train_loss'], info['test_loss'])\n",
    "    print(message)\n",
    "\n",
    "\n",
    "def run(model, train_loader, test_loader, num_nodes, epochs, optimizer, device):\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        t = time.time()\n",
    "        train_loss = train(model, train_loader, optimizer, device)\n",
    "        t_duration = time.time() - t\n",
    "        test_loss = test(model, test_loader, num_nodes, device)\n",
    "        eval_info = {\n",
    "            'train_loss': train_loss,\n",
    "            'test_loss': test_loss,\n",
    "            'current_epoch': epoch,\n",
    "            'epochs': epochs,\n",
    "            't_duration': t_duration\n",
    "        }\n",
    "\n",
    "        print_info(eval_info)\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        #log_probs = F.log_softmax(output, dim=1).double()\n",
    "        #print(log_probs.dtype)\n",
    "        #print(data.y.dtype)\n",
    "        loss = F.mse_loss(output, data.y.to(device))\n",
    "        \n",
    "        #loss = model.compute_loss(output, data.y)  # compute loss with L1 regularization\n",
    "        #loss = F.nll_loss(log_probs, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def test(model, test_loader, num_nodes, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    n_graphs = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(test_loader):\n",
    "            out = model(data.to(device))\n",
    "            total_loss += F.mse_loss(out, data.y.to(device)).item()\n",
    "            #pred = out.max(1)[1]\n",
    "            #correct += pred.eq(data.y).sum().item()\n",
    "            #n_graphs += data.num_graphs\n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Duration: 13.976s,Train Loss: 3.7278, Test Loss:1.7363\n",
      "Epoch: 2/100, Duration: 14.551s,Train Loss: 1.8031, Test Loss:0.8992\n",
      "Epoch: 3/100, Duration: 15.557s,Train Loss: 1.1338, Test Loss:0.5917\n",
      "Epoch: 4/100, Duration: 15.555s,Train Loss: 0.9340, Test Loss:0.4018\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[39m=\u001b[39m ArchNN(num_features, num_nodes, heads\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device_name)\n\u001b[0;32m      7\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(),\n\u001b[0;32m      8\u001b[0m                        lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m run(model, train_loader, test_loader, num_nodes, \u001b[39m100\u001b[39;49m, optimizer, device_name)\n",
      "Cell \u001b[1;32mIn[32], line 18\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(model, train_loader, test_loader, num_nodes, epochs, optimizer, device)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m     17\u001b[0m     t \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 18\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_loader, optimizer, device)\n\u001b[0;32m     19\u001b[0m     t_duration \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t\n\u001b[0;32m     20\u001b[0m     test_loss \u001b[39m=\u001b[39m test(model, test_loader, num_nodes, device)\n",
      "Cell \u001b[1;32mIn[32], line 38\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, device)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m idx, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m     37\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 38\u001b[0m     output \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mto(device))\n\u001b[0;32m     39\u001b[0m     \u001b[39m#log_probs = F.log_softmax(output, dim=1).double()\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[39m#print(log_probs.dtype)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[39m#print(data.y.dtype)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(output, data\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mto(device))\n",
      "File \u001b[1;32mc:\\Users\\kt\\OneDrive - NTNU\\Master thesis\\03_Herman\\masters2023\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[31], line 28\u001b[0m, in \u001b[0;36mArchNN.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m     27\u001b[0m     x, edge_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index\n\u001b[1;32m---> 28\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39melu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc0(x))\n\u001b[0;32m     29\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39melu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x, edge_index))\n\u001b[0;32m     30\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39melu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x, edge_index))\n",
      "File \u001b[1;32mc:\\Users\\kt\\OneDrive - NTNU\\Master thesis\\03_Herman\\masters2023\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kt\\OneDrive - NTNU\\Master thesis\\03_Herman\\masters2023\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#runner\n",
    "num_nodes = train_loader[0].x.shape[0]\n",
    "num_features = train_loader[0].x.shape[1]\n",
    "\n",
    "model = ArchNN(num_features, num_nodes, heads=1).to(device_name)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=0.001)\n",
    "\n",
    "\n",
    "run(model, train_loader, test_loader, num_nodes, 100, optimizer, device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.3550,  0.1630,  0.9600,  1.1790,  0.9760,  0.5080, -0.0740, -0.6390,\n",
      "        -1.0780, -1.3180, -1.3180, -1.0780, -0.6390, -0.0740,  0.5080,  0.9760,\n",
      "         1.1790,  0.9600,  0.1630, -1.3550])\n",
      "tensor([ 1.4588,  0.0168,  0.9337,  1.0978,  0.8159,  0.3859, -0.1911, -0.7819,\n",
      "        -1.2410, -1.4660, -1.4306, -1.0969, -0.5489,  0.1082,  0.5618,  0.9636,\n",
      "         1.3206,  0.9643,  0.0294, -1.8978], grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 1.6200,  0.1130,  1.0340,  1.3030,  1.0950,  0.5870, -0.0530, -0.6770,\n",
      "        -1.1640, -1.4290, -1.4290, -1.1640, -0.6770, -0.0530,  0.5870,  1.0950,\n",
      "         1.3030,  1.0340,  0.1130, -1.6200])\n",
      "tensor([ 1.7416, -0.0129,  1.0249,  1.2137,  0.9230,  0.4418, -0.1897, -0.8252,\n",
      "        -1.3337, -1.5737, -1.4708, -1.0195, -0.3363,  0.4624,  0.9845,  1.3977,\n",
      "         1.5277,  1.0012, -0.6278, -2.5273], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "model_tester_data = \"testdata.txt\"\n",
    "model_tester_dataset = create_dataset(model_tester_data)\n",
    "\n",
    "print(model_tester_dataset[0].y)\n",
    "tester = model(model_tester_dataset[0].to(device_name))\n",
    "\n",
    "print(tester)\n",
    "\n",
    "print(model_tester_dataset[1].y)\n",
    "tester2 = model(model_tester_dataset[1].to(device_name))\n",
    "print(tester2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss=27.194686889648438\n",
      "Epoch 1: loss=23.968759536743164\n",
      "Epoch 2: loss=21.4787540435791\n",
      "Epoch 3: loss=19.75748062133789\n",
      "Epoch 4: loss=18.83110237121582\n",
      "Epoch 5: loss=18.46010971069336\n",
      "Epoch 6: loss=18.401479721069336\n",
      "Epoch 7: loss=18.3200740814209\n",
      "Epoch 8: loss=18.0425968170166\n",
      "Epoch 9: loss=17.594493865966797\n",
      "Epoch 10: loss=17.073143005371094\n",
      "Epoch 11: loss=16.612995147705078\n",
      "Epoch 12: loss=16.298181533813477\n",
      "Epoch 13: loss=16.103126525878906\n",
      "Epoch 14: loss=16.005006790161133\n",
      "Epoch 15: loss=15.95953369140625\n",
      "Epoch 16: loss=15.92503547668457\n",
      "Epoch 17: loss=15.877996444702148\n",
      "Epoch 18: loss=15.810765266418457\n",
      "Epoch 19: loss=15.72706127166748\n",
      "Epoch 20: loss=15.643503189086914\n",
      "Epoch 21: loss=15.57574462890625\n",
      "Epoch 22: loss=15.531913757324219\n",
      "Epoch 23: loss=15.508995056152344\n",
      "Epoch 24: loss=15.494709968566895\n",
      "Epoch 25: loss=15.474119186401367\n",
      "Epoch 26: loss=15.437162399291992\n",
      "Epoch 27: loss=15.396413803100586\n",
      "Epoch 28: loss=15.341238021850586\n",
      "Epoch 29: loss=15.272732734680176\n",
      "Epoch 30: loss=15.215484619140625\n",
      "Epoch 31: loss=15.18469524383545\n",
      "Epoch 32: loss=15.162510871887207\n",
      "Epoch 33: loss=15.140666007995605\n",
      "Epoch 34: loss=15.1116361618042\n",
      "Epoch 35: loss=15.071574211120605\n",
      "Epoch 36: loss=15.033129692077637\n",
      "Epoch 37: loss=14.992965698242188\n",
      "Epoch 38: loss=14.947591781616211\n",
      "Epoch 39: loss=14.900650024414062\n",
      "Epoch 40: loss=14.877293586730957\n",
      "Epoch 41: loss=14.851730346679688\n",
      "Epoch 42: loss=14.817270278930664\n",
      "Epoch 43: loss=14.772893905639648\n",
      "Epoch 44: loss=14.725802421569824\n",
      "Epoch 45: loss=14.690373420715332\n",
      "Epoch 46: loss=14.644685745239258\n",
      "Epoch 47: loss=14.619364738464355\n",
      "Epoch 48: loss=14.58965015411377\n",
      "Epoch 49: loss=14.552943229675293\n",
      "Epoch 50: loss=14.507730484008789\n",
      "Epoch 51: loss=14.461618423461914\n",
      "Epoch 52: loss=14.419944763183594\n",
      "Epoch 53: loss=14.36890697479248\n",
      "Epoch 54: loss=14.32396125793457\n",
      "Epoch 55: loss=14.280107498168945\n",
      "Epoch 56: loss=14.231744766235352\n",
      "Epoch 57: loss=14.186758041381836\n",
      "Epoch 58: loss=14.161712646484375\n",
      "Epoch 59: loss=14.12987232208252\n",
      "Epoch 60: loss=14.085469245910645\n",
      "Epoch 61: loss=14.046224594116211\n",
      "Epoch 62: loss=13.989375114440918\n",
      "Epoch 63: loss=13.950770378112793\n",
      "Epoch 64: loss=13.906529426574707\n",
      "Epoch 65: loss=13.858988761901855\n",
      "Epoch 66: loss=13.80235481262207\n",
      "Epoch 67: loss=13.751245498657227\n",
      "Epoch 68: loss=13.706174850463867\n",
      "Epoch 69: loss=13.634160995483398\n",
      "Epoch 70: loss=13.585428237915039\n",
      "Epoch 71: loss=13.54632568359375\n",
      "Epoch 72: loss=13.47564697265625\n",
      "Epoch 73: loss=13.437359809875488\n",
      "Epoch 74: loss=13.39153003692627\n",
      "Epoch 75: loss=13.322637557983398\n",
      "Epoch 76: loss=13.23725414276123\n",
      "Epoch 77: loss=13.235748291015625\n",
      "Epoch 78: loss=13.165998458862305\n",
      "Epoch 79: loss=13.037338256835938\n",
      "Epoch 80: loss=12.9708890914917\n",
      "Epoch 81: loss=12.879816055297852\n",
      "Epoch 82: loss=12.77706241607666\n",
      "Epoch 83: loss=12.696346282958984\n",
      "Epoch 84: loss=12.588312149047852\n",
      "Epoch 85: loss=12.515447616577148\n",
      "Epoch 86: loss=12.426271438598633\n",
      "Epoch 87: loss=12.372831344604492\n",
      "Epoch 88: loss=12.30498218536377\n",
      "Epoch 89: loss=12.214488983154297\n",
      "Epoch 90: loss=12.112728118896484\n",
      "Epoch 91: loss=12.005380630493164\n",
      "Epoch 92: loss=11.942048072814941\n",
      "Epoch 93: loss=11.788455963134766\n",
      "Epoch 94: loss=11.69173812866211\n",
      "Epoch 95: loss=11.584510803222656\n",
      "Epoch 96: loss=11.47330379486084\n",
      "Epoch 97: loss=11.385019302368164\n",
      "Epoch 98: loss=11.250876426696777\n",
      "Epoch 99: loss=11.135069847106934\n",
      "tensor([[0, 1, 1, 2, 2, 3, 3, 4],\n",
      "        [1, 0, 2, 1, 3, 2, 4, 3]])\n"
     ]
    }
   ],
   "source": [
    "#OLD\n",
    "# Define a simple GNN model\n",
    "class MyGNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MyGNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Define a simple training function for the GNN model\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    loss = F.mse_loss(output, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Define a simple testing function for the GNN model\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    return output\n",
    "\n",
    "# Set up the input data\n",
    "x = torch.tensor([\n",
    "    [0,0,1,1,1,0,0,0],\n",
    "    [10,5,0,0,0,0,5,0],\n",
    "    [20,10,0,0,0,0,5,0],\n",
    "    [30,5,0,0,0,0,5,0],\n",
    "    [40,0,1,1,1,0,0,0]\n",
    "], dtype=torch.float)\n",
    "\n",
    "edge_index = torch.tensor([\n",
    "    [0,1], [1,0], [1,2], [2,1], [2,3], [3,2], [3,4], [4,3]\n",
    "], dtype=torch.long).t()\n",
    "\n",
    "# Set up the output data (nodal forces and moments)\n",
    "y = torch.tensor([\n",
    "    [0,0,0,0,0,10,20,0],\n",
    "    [0,0,0,0,0,5,0,0],\n",
    "    [0,0,0,0,0,5,0,0],\n",
    "    [0,0,0,0,0,5,0,0],\n",
    "    [0,0,0,0,0,10,20,0]\n",
    "], dtype=torch.float)\n",
    "\n",
    "# Create a Data object that encapsulates the input and output data\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Initialize the GNN model\n",
    "input_dim = x.shape[1]\n",
    "output_dim = y.shape[1]\n",
    "hidden_dim = 16\n",
    "model = MyGNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the optimizer and the number of epochs for training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "num_epochs = 100\n",
    "\n",
    "# Train the GNN model\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train(model, data, optimizer)\n",
    "    print('Epoch {}: loss={}'.format(epoch, loss))\n",
    "\n",
    "# Test the GNN model on a new input example\n",
    "x_new = torch.tensor([\n",
    "    [0,0,1,1,1,0,0,0],\n",
    "    [10,5,0,0,0,0,5,0],\n",
    "    [20,10,0,0,0,0,5,0],\n",
    "    [30,5,0,0,0,0,5,0]\n",
    "])\n",
    "print(edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f155e3810749e3e5c86d0714d9f4acbbc66b2c24e666ad929ed58436b422284a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
